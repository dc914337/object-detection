
resolution: &resolution 36
patch_size: &patch_size 3
num_classes: &num_classes 4


model_class:  VIT_MADVERSARY_2

model:
  image_size: *resolution
  patch_size: *patch_size
  num_classes: *num_classes

  # masker
  masker:
    image_size: *resolution
    patch_size: *patch_size

    num_hidden_layers: 3
    num_attention_heads: 4
    hidden_size: 128

    intermediate_size: 260

    decoder_intermediate_size: 130
    decoder_num_hidden_layers: 3
    decoder_num_attention_heads: 4
    decoder_hidden_size: 128

    # custom parameter
    decoder_num_classes: 4

    pretrained_path: null
    #pretrained_path: "./checkpoints/whole recon both/masker_madversary_2_294000.pt"
    #pretrained_path: "./checkpoints/softmax masker/masker_madversary_2_2000.pt"

  # reconstructor
  reconstructor:
    image_size: *resolution
    patch_size: *patch_size

    num_hidden_layers: 3
    num_attention_heads: 4
    hidden_size: 128

    intermediate_size: 260

    decoder_intermediate_size: 130
    decoder_num_hidden_layers: 3
    decoder_num_attention_heads: 4
    decoder_hidden_size: 128

    #pretrained_path: null
    #pretrained_path: "./checkpoints/whole recon both/recon_madversary_2_222000.pt"
    #pretrained_path: "./checkpoints/softmax recon/recon_madversary_2_1000.pt"
    #pretrained_path: "./checkpoints/tiny recon/recon_madversary_2_10000.pt"
    #pretrained_path: "./checkpoints/tiny recon/recon_madversary_2_25000.pt"
    #pretrained_path: "./checkpoints/tiny recon/recon_madversary_2_35000.pt"
    pretrained_path: "./checkpoints/whole tiny recon/recon_madversary_2_38000.pt"
    #pretrained_path: "./checkpoints/recon_madversary_2_11000.pt"


  object_size: 0.08 #0.5 #0.18
  temperature: 0.01
  lr: 1.e-3
  warmup_steps: 5000
  decay_rate: 0.1
  decay_steps: 150000
  norm_pix_loss: False

# training
total_iter: 400000
visualize_freq: 300

switch_training_recon_masker_steps: 100000

eval_epoch_freq: 1
dataset_path: "data/EMORL/tetrominoes.h5"
test_dataset_path: "data/EMORL/tetrominoes_test.h5"
batch_size: 90
DEBUG: False

notes: "Schedulling to find the best lr for masker and reconstructor, starting from training masker with pretrained reconstructor for 100k steps, switching every 100k"
train_recon: False